{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ensamble - Voting Classifier  \r\n",
    "\r\n",
    "### The idea behind the VotingClassifier is to combine concptually different machine learning classifiers and use a majority vote or the average predicted probablities (soft vote) to predict the class labels. such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.  \r\n",
    "\r\n",
    "### - **Majority Class Labels (Majority/Hard Voting):** In majority voting, the predicted calss label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.<br> E.g. If the prediction for a given sample is:  \r\n",
    "- classifier 1 --> class 1\r\n",
    "- classifier 2 --> class 1\r\n",
    "- classifier 3 --> class 2  \r\n",
    "### The Voting Classifier would classify the sample as 'class 1' based on the majority class label.  \r\n",
    "### In the case of a tie, the *VotingClassifier* will select the class based on the ascending sort order. <br> E.g. in the following scenario:\r\n",
    "- classifier 1 --> class 2\r\n",
    "- classifier 2 --> class 1\r\n",
    "### the class label 1 will be assigned to the sample. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usage:\r\n",
    "\r\n",
    "The following example shows how to fit the majority rule classifier:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Importing the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# iris = datasets.load_iris()\n",
    "# X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "# # Generating the 3 classifiers\n",
    "# clf1 = LogisticRegression(random_state=12)\n",
    "# clf2 = RandomForestClassifier(n_estimators=50, random_state=12)\n",
    "# clf3 = GaussianNB()\n",
    "\n",
    "# # Creating the ensamble classifier\n",
    "# eclf = VotingClassifier(\n",
    "#     estimators=[('lr', clf1), ('rf', clf2), ('nb', clf3)], \n",
    "#     voting='hard') # Voting = hard  ->  Majority voting\n",
    "\n",
    "# # Training and testing the models with the cross validation procedure\n",
    "# for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensable']):\n",
    "#     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
    "#     print(f'Accuracy: {scores.mean():.2} (+/- {scores.std():.2f}) [{label}]')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Trying to do the Ensamble without the Voting Classifier**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Opening the Cancer dataset\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# Generating the X and y data structures\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Defining the ML models that will be part of the ensemble\n",
    "svm_model = SVC(kernel='rbf', C=100, gamma=1)\n",
    "nb_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=6)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Defining the ML models that already are ensemble models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, eval_metric='logloss')\n",
    "\n",
    "models_dict = {'SVM': svm_model, \n",
    "                'NB': nb_model,\n",
    "                'kNN': knn_model,\n",
    "                'DT': dt_model}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def cross_validation_ensemble_00(ensemble, X, y, folds=10):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "    scores = {\\\n",
    "            'auc':[], \\\n",
    "            'accuracy': [], \\\n",
    "            'f1': [], \\\n",
    "            'precision': [], \\\n",
    "            'recall': []}\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X,y): \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Storing the final prediction results\n",
    "        ensemble_pred = [] \n",
    "\n",
    "        # I will train and test each of the model that are part of the ensamble on each of the training and test subset of the CV\n",
    "        for model in ensemble:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            if len(ensemble_pred) == 0:\n",
    "                ensemble_pred = [[x] for x in y_pred]\n",
    "            else:\n",
    "                for idx, el in enumerate(y_pred):\n",
    "                    ensemble_pred[idx].append(el)\n",
    "\n",
    "        # Extracting the class that has been majority voted by the models\n",
    "        for idx, li in enumerate(ensemble_pred):\n",
    "            pred = li[0]\n",
    "            count = 0\n",
    "            for el in li:\n",
    "                freq_el = li.count(el)\n",
    "                if freq_el > count:\n",
    "                    count = freq_el\n",
    "                    pred = el\n",
    "\n",
    "            ensemble_pred[idx] = pred\n",
    "\n",
    "        scores['auc'].append(roc_auc_score(list(y_test), ensemble_pred))\n",
    "        scores['accuracy'].append(accuracy_score(list(y_test), ensemble_pred))\n",
    "        scores['f1'].append(f1_score(list(y_test), ensemble_pred))\n",
    "        scores['precision'].append(precision_score(list(y_test), ensemble_pred))\n",
    "        scores['recall'].append(recall_score(list(y_test), ensemble_pred))\n",
    "\n",
    "    # This will print all the scores from the k-folds\n",
    "    scores = {k: np.mean(v) for k, v in scores.items()}\n",
    "\n",
    "    print(scores)\n",
    "\n",
    "\n",
    "print('Ensemble:')\n",
    "cross_validation_ensemble_00([svm_model, nb_model, knn_model, dt_model], X, y, folds=10)\n",
    "print('SVM:')\n",
    "cross_validation_ensemble_00([svm_model], X, y, folds=10)\n",
    "print('NB:')\n",
    "cross_validation_ensemble_00([nb_model], X, y, folds=10)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ensemble:\n",
      "{'auc': 0.8992568542568543, 'accuracy': 0.9225877192982456, 'f1': 0.9417465274711129, 'precision': 0.8972561531611596, 'recall': 0.9915873015873016}\n",
      "SVM:\n",
      "{'auc': 0.5, 'accuracy': 0.6274122807017544, 'f1': 0.7710324738375229, 'precision': 0.6274122807017544, 'recall': 1.0}\n",
      "NB:\n",
      "{'auc': 0.93258658008658, 'accuracy': 0.9420426065162907, 'f1': 0.9545395306077561, 'precision': 0.9409422934655133, 'recall': 0.9692857142857143}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Trying with the 192 proteins dataset and with the correspondin best features**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Importing the Dataset\n",
    "lisbon_coimbra_df = pd.read_excel('190 proteins quantified_analysis.xls', sheet_name='Lisbon_Coimbra_proteomics')\n",
    "\n",
    "# Generating the y array\n",
    "y = np.array([1 if i == 'Amyloid-Positive' else 2 for i in lisbon_coimbra_df['Group']]) # 1 -> A+ ; 2 -> A-\n",
    "# print(f'- The number of Amyloid-Positive patients is: {list(y).count(1)} \\n- The number of Amyloid-Negative patients is: {list(y).count(2)} \\n')\n",
    "\n",
    "# Dropping the useless columns\n",
    "lisbon_coimbra_df = lisbon_coimbra_df.drop(['Sample Name','Group'], axis=1)\n",
    "\n",
    "# # Generating the X array \n",
    "X = lisbon_coimbra_df.values\n",
    "# print(f'The final X matrix is made out of: {X.shape[0]} examples and {X.shape[1]} features')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "svm_dataset = lisbon_coimbra_df[['P02768_ALBU', 'P02765_FETUA']]\n",
    "\n",
    "knn_dataset = lisbon_coimbra_df[['P02765_FETUA', 'Q16270_IBP7', 'P02749_APOH', 'P05090_APOD', 'P09486_SPRC', 'P51693_APLP1', 'P00338_LDHA', 'P05155_IC1', 'P13987_CD59', 'P41271_NBL1', 'P01011_AACT', 'P06727_APOA4', 'Q9UBX5_FBLN5', 'P02750_A2GL']]\n",
    "\n",
    "nb_dataset = lisbon_coimbra_df[['P02765_FETUA', 'Q16270_IBP7', 'P09486_SPRC', 'P41271_NBL1', 'P01011_AACT', 'P13987_CD59', 'Q9UBX5_FBLN5', 'P24592_IBP6', 'P02766_TTHY', 'P05155_IC1', 'P08294_SODE', 'Q08380_LG3BP', 'P02747_C1QC', 'Q969P0_IGSF8', 'P06396_GELS', 'P05090_APOD', 'P61916_NPC2', 'P01024_CO3', 'P22352_GPX3', 'P10643_CO7', 'P02751_FINC', 'P02749_APOH', 'P25311_ZA2G']]\n",
    "\n",
    "rf_dataset = lisbon_coimbra_df[['P02765_FETUA', 'Q16270_IBP7', 'P09486_SPRC', 'P41271_NBL1', 'P01011_AACT', 'P13987_CD59', 'Q9UBX5_FBLN5']]\n",
    "\n",
    "xgb_dataset = lisbon_coimbra_df[['P24592_IBP6', 'P02766_TTHY', 'P05155_IC1', 'P08294_SODE', 'Q08380_LG3BP', 'P02747_C1QC', 'Q969P0_IGSF8', 'P06396_GELS', 'P05090_APOD', 'P61916_NPC2', 'P01024_CO3', 'P22352_GPX3', 'P10643_CO7', 'P02751_FINC']]\n",
    "\n",
    "model_dataset_dict = {'svm': (svm_model, svm_dataset), 'knn': (knn_model, knn_dataset), 'nb': (nb_model, nb_dataset)}\n",
    "\n",
    "ensemble_dataset_dict = {'rf': (rf_model, rf_dataset), 'xgb': (xgb_model, xgb_dataset)}  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def cross_validation_ensemble(model_dataset_dict, X, y, folds=10):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    scores = {\\\n",
    "                'auc':[], \\\n",
    "                'accuracy': [], \\\n",
    "                'f1': [], \\\n",
    "                'precision': [], \\\n",
    "                'recall': []}\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X,y): \n",
    "    \n",
    "        ensemble_pred = []\n",
    "        y_pred_ensemble = list()\n",
    "    \n",
    "        for key, values in model_dataset_dict.items():\n",
    "            \n",
    "            # The X matrix will contain the best features for each of the model\n",
    "            X_temp = values[1].values\n",
    "    \n",
    "            # Splitting the X matrix in train and test using the cv.split function (this spit will be the same for each of the model)\n",
    "            X_train, X_test = X_temp[train_idx], X_temp[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "            # Fitting the model\n",
    "            values[0].fit(X_train, y_train)\n",
    "\n",
    "            # Predictig the class of the X_test dataset\n",
    "            y_pred = values[0].predict(X_test)\n",
    "    \n",
    "            # Storing the y_pred result in the ensemble pred array\n",
    "            if len(ensemble_pred) == 0:\n",
    "                ensemble_pred = [[x] for x in y_pred]\n",
    "            else:\n",
    "                for idx, el in enumerate(y_pred):\n",
    "                    ensemble_pred[idx].append(el)\n",
    "    \n",
    "        # Extracting the class that has been majority voted from the different models\n",
    "        for idx, li in enumerate(ensemble_pred):\n",
    "            pred = li[0]\n",
    "            count = 0\n",
    "            for el in li:\n",
    "                freq_el = li.count(el)\n",
    "                if freq_el > count:\n",
    "                    count = freq_el\n",
    "                    pred = el\n",
    "            y_pred_ensemble.append(pred)\n",
    "\n",
    "        print(y_pred_ensemble)\n",
    "\n",
    "        # Computing the scoring metrics\n",
    "        scores['auc'].append(roc_auc_score(y_test, y_pred_ensemble))\n",
    "        scores['accuracy'].append(accuracy_score(y_test, y_pred_ensemble))\n",
    "        scores['f1'].append(f1_score(y_test, y_pred_ensemble))\n",
    "        scores['precision'].append(precision_score(y_test, y_pred_ensemble))\n",
    "        scores['recall'].append(recall_score(y_test, y_pred_ensemble))\n",
    "    \n",
    "    # Computing the mean of the k-fold-CV for each of the scoring metrics f\n",
    "    scores = {k: np.mean(v) for k, v in scores.items()}\n",
    "\n",
    "    return scores, y_pred_ensemble\n",
    "    \n",
    "\n",
    "final_scores, y_ensemble = cross_validation_ensemble(model_dataset_dict, X, y, folds=10)\n",
    "\n",
    "print('final ensemble:')\n",
    "print(y_ensemble)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]\n",
      "[2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1]\n",
      "[2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1]\n",
      "[1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
      "[2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1]\n",
      "[1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1]\n",
      "[1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1]\n",
      "[2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1]\n",
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1]\n",
      "final ensemble:\n",
      "[1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "def cross_validation_ensemble(model_dataset_dict, X, y, folds=10):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    scores = {\\\n",
    "                'auc':[], \\\n",
    "                'accuracy': [], \\\n",
    "                'f1': [], \\\n",
    "                'precision': [], \\\n",
    "                'recall': []}\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X,y): \n",
    "    \n",
    "        ensemble_pred = []\n",
    "        y_pred_ensemble = list()\n",
    "    \n",
    "        for key, values in model_dataset_dict.items():\n",
    "            \n",
    "            # The X matrix will contain the best features for each of the model\n",
    "            X_temp = values[1].values\n",
    "    \n",
    "            # Splitting the X matrix in train and test using the cv.split function (this spit will be the same for each of the model)\n",
    "            X_train, X_test = X_temp[train_idx], X_temp[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "            # Fitting the model\n",
    "            values[0].fit(X_train, y_train)\n",
    "\n",
    "            # Predictig the class of the X_test dataset\n",
    "            y_pred = values[0].predict(X_test)\n",
    "    \n",
    "            # Storing the y_pred result in the ensemble pred array\n",
    "            if len(ensemble_pred) == 0:\n",
    "                ensemble_pred = [[x] for x in y_pred]\n",
    "            else:\n",
    "                for idx, el in enumerate(y_pred):\n",
    "                    ensemble_pred[idx].append(el)\n",
    "    \n",
    "        # Extracting the class that has been majority voted from the different models\n",
    "        for idx, li in enumerate(ensemble_pred):\n",
    "            pred = li[0]\n",
    "            count = 0\n",
    "            for el in li:\n",
    "                freq_el = li.count(el)\n",
    "                if freq_el > count:\n",
    "                    count = freq_el\n",
    "                    pred = el\n",
    "            y_pred_ensemble.append(pred)\n",
    "\n",
    "        # print(y_pred_ensemble)\n",
    "\n",
    "        # Computing the scoring metrics\n",
    "        scores['auc'].append(roc_auc_score(y_test, y_pred_ensemble))\n",
    "        scores['accuracy'].append(accuracy_score(y_test, y_pred_ensemble))\n",
    "        scores['f1'].append(f1_score(y_test, y_pred_ensemble))\n",
    "        scores['precision'].append(precision_score(y_test, y_pred_ensemble))\n",
    "        scores['recall'].append(recall_score(y_test, y_pred_ensemble))\n",
    "    \n",
    "    # Computing the mean of the k-fold-CV for each of the scoring metrics f\n",
    "    scores = {k: np.mean(v) for k, v in scores.items()}\n",
    "\n",
    "    return scores, y_pred_ensemble\n",
    "\n",
    "final_scores, y_ensemble = cross_validation_ensemble(model_dataset_dict, X, y, folds=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble of ensemble"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "# cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# for train_idx, test_idx in cv.split(X,y): \n",
    "#     continue\n",
    "\n",
    "def ensemble_test(model_dataset_dict, train_idx, test_idx, y):\n",
    "\n",
    "    ensemble_pred = []\n",
    "    y_pred_ensemble = list()\n",
    "\n",
    "    for key, values in model_dataset_dict.items():    \n",
    "        \n",
    "        # The X matrix will contain the best features for each of the model\n",
    "        X_temp = values[1].values\n",
    "        # print(len(X_temp))\n",
    "\n",
    "        # Splitting the X matrix in train and test using the cv.split function (this spit will be the same for each of the model)\n",
    "        X_train, X_test = X_temp[train_idx], X_temp[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Fitting the model\n",
    "        values[0].fit(X_train, y_train)\n",
    "\n",
    "        # Predictig the class of the X_test dataset\n",
    "        y_pred = values[0].predict(X_test)\n",
    "\n",
    "        # Storing the y_pred result in the ensemble pred array\n",
    "        if len(ensemble_pred) == 0:\n",
    "            ensemble_pred = [[x] for x in y_pred]\n",
    "        else:\n",
    "            for idx, el in enumerate(y_pred):\n",
    "                ensemble_pred[idx].append(el)\n",
    "\n",
    "    # Finding and saving the most voted class\n",
    "    for idx, li in enumerate(ensemble_pred):\n",
    "            pred = li[0]\n",
    "            count = 0\n",
    "            for el in li:\n",
    "                freq_el = li.count(el)\n",
    "                if freq_el > count:\n",
    "                    count = freq_el\n",
    "                    pred = el\n",
    "            y_pred_ensemble.append(pred)\n",
    "    \n",
    "    return y_pred_ensemble\n",
    "\n",
    "# y_pred_ensemble = ensemble_test(model_dataset_dict, train_idx, test_idx, y)\n",
    "\n",
    "# print(y_pred_ensemble)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "def cross_validation_ensemble_1(model_dataset_dict, ensemble_dataset_dict, X, y, folds=10):\n",
    "    \n",
    "    # y = [int(0) if i == 1 else int(1) for i in y]\n",
    "\n",
    "    # print(y)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True)\n",
    "    \n",
    "    scores = {\\\n",
    "                'auc':[], \\\n",
    "                'accuracy': [], \\\n",
    "                'f1': [], \\\n",
    "                'precision': [], \\\n",
    "                'recall': []}\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X,y): \n",
    "\n",
    "        ensemble_pred = []\n",
    "        y_pred_ensemble = list()\n",
    "\n",
    "        # print(len(train_idx))\n",
    "        # print(len(test_idx))\n",
    "\n",
    "        y_ensemble = ensemble_test(model_dataset_dict, train_idx, test_idx, y)   \n",
    "\n",
    "        # print('Models_ensemble result:')\n",
    "        # print(y_ensemble, 'len:', len(y_ensemble))    \n",
    "\n",
    "        for key, values in ensemble_dataset_dict.items():\n",
    "\n",
    "            # The X matrix will contain the best features for each of the model\n",
    "            X_temp = values[1].values\n",
    "    \n",
    "            # Splitting the X matrix in train and test using the cv.split function (this spit will be the same for each of the model)\n",
    "            X_train, X_test = X_temp[train_idx], X_temp[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Fitting the model\n",
    "            values[0].fit(X_train, y_train)\n",
    "\n",
    "            # Predictig the class of the X_test dataset\n",
    "            y_pred = values[0].predict(X_test)    \n",
    "\n",
    "            # print(y_pred, 'len :', len(y_pred))  \n",
    "\n",
    "            # Storing the y_pred result in the ensemble pred array\n",
    "            if len(ensemble_pred) == 0:\n",
    "                ensemble_pred = [[x] for x in y_pred]\n",
    "            else:\n",
    "                for idx, el in enumerate(y_pred):\n",
    "                    ensemble_pred[idx].append(el)\n",
    "        \n",
    "        # Adding the results of the model ensemble\n",
    "        for i, pred in enumerate(y_ensemble):\n",
    "            ensemble_pred[i].append(pred)\n",
    "\n",
    "        # Finding and saving the most voted class\n",
    "        for idx, li in enumerate(ensemble_pred):\n",
    "                pred = li[0]\n",
    "                count = 0\n",
    "                for el in li:\n",
    "                    freq_el = li.count(el)\n",
    "                    if freq_el > count:\n",
    "                        count = freq_el\n",
    "                        pred = el\n",
    "                y_pred_ensemble.append(pred)\n",
    "\n",
    "        # print('Final Result')\n",
    "        # print(y_pred_ensemble)\n",
    "        # print(y_test)\n",
    "\n",
    "        scores['auc'].append(roc_auc_score(y_test, y_pred_ensemble))\n",
    "        scores['accuracy'].append(accuracy_score(y_test, y_pred_ensemble))\n",
    "        scores['f1'].append(f1_score(y_test, y_pred_ensemble))\n",
    "        scores['precision'].append(precision_score(y_test, y_pred_ensemble))\n",
    "        scores['recall'].append(recall_score(y_test, y_pred_ensemble))\n",
    "\n",
    "    # print(scores)\n",
    "    \n",
    "    scores = {k: np.mean(v) for k, v in scores.items()}\n",
    "\n",
    "    return scores\n",
    "\n",
    "final_scores = cross_validation_ensemble_1(model_dataset_dict, ensemble_dataset_dict, X, y, folds=5)\n",
    "\n",
    "print(final_scores)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'auc': 0.926073926073926, 'accuracy': 0.9283076923076923, 'f1': 0.9353360560257112, 'precision': 0.9052106227106227, 'recall': 0.9703296703296704}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression (LR)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creating a dict in which I will store the results\n",
    "scores = {\\\n",
    "            'auc':[], \\\n",
    "            'accuracy': [], \\\n",
    "            'f1': [], \\\n",
    "            'precision': [], \\\n",
    "            'recall': []}\n",
    "\n",
    "# Splitting the dataset in training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Creating the model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model \n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the y_test\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Computing the scoring metrics\n",
    "scores['auc'].append(roc_auc_score(y_test, y_pred))\n",
    "scores['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "scores['f1'].append(f1_score(y_test, y_pred))\n",
    "scores['precision'].append(precision_score(y_test, y_pred))\n",
    "scores['recall'].append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(scores)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'auc': [0.5], 'accuracy': [0.5238095238095238], 'f1': [0.6875000000000001], 'precision': [0.5238095238095238], 'recall': [1.0]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Deviation (Standard Error)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "def cross_validate_balancing(estimator, X, y, balance = SMOTE(), folds=10):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits = folds, shuffle = True) \n",
    "    scores = {\\\n",
    "            'auc':[], \\\n",
    "            'accuracy': [], \\\n",
    "            'f1': [], \\\n",
    "            'precision': [], \\\n",
    "            'recall': []}\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X,y): \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        if balance != 'None':\n",
    "            X_train, y_train = balance.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator.fit(X_train, y_train)\n",
    "        y_predicted = estimator.predict(X_test)\n",
    "\n",
    "        scores['auc'].append(roc_auc_score(y_test, y_predicted))\n",
    "        scores['accuracy'].append(accuracy_score(y_test, y_predicted))\n",
    "        scores['f1'].append(f1_score(y_test, y_predicted))\n",
    "        scores['precision'].append(precision_score(y_test, y_predicted))\n",
    "        scores['recall'].append(recall_score(y_test, y_predicted))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def cv_iteration(model, X, y, iterations=10, folds=10):\n",
    "    \n",
    "    # Defining the final dictionary that will contain the scores\n",
    "    iter_result_no_smote = {}\n",
    "    # iter_result_smote = {}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        if _ % 2 == 0:\n",
    "            # clear_output(wait=True)\n",
    "            print(f'{(_/iterations)*100}%', end=' -> ')\n",
    "\n",
    "        result_no_smote = cross_validate_balancing(model, X, y, balance='None', folds=folds) # Calling the CV function withOUT SMOTE\n",
    "        # result_smote = cross_validate_balancing(model, X, y, folds=folds) # Calling the CV function with SMOTE\n",
    "        result_no_smote = {k: np.mean(v) for k, v in result_no_smote.items()}\n",
    "        # result_smote = {k: np.mean(v) for k, v in result_smote.items()}\n",
    "\n",
    "        # Filling the dictionary with the resuts obtained WITHOUT applying SMOTE\n",
    "        for k, v in result_no_smote.items():\n",
    "            if k in iter_result_no_smote.keys():\n",
    "                iter_result_no_smote[k].append(v)\n",
    "            else:\n",
    "                iter_result_no_smote[k] = [v]\n",
    "    \n",
    "    # computing the standard deviation\n",
    "    sd_dict = {}\n",
    "\n",
    "    for k, v in iter_result_no_smote.items():\n",
    "        sd_dict[k] = np.std(v)  \n",
    "                \n",
    "    iter_result_no_smote = {k: np.mean(v) for k, v in iter_result_no_smote.items()}\n",
    "    # iter_result_smote = {k: np.mean(v) for k, v in iter_result_smote.items()}\n",
    "\n",
    "    return iter_result_no_smote, sd_dict # iter_result_smote\n",
    "    \n",
    "\n",
    "\n",
    "def cross_validate(models_dict, X, y, iterations=10, folds=10):\n",
    "\n",
    "    results_no_smote_df = pd.DataFrame()\n",
    "    # results_smote_df = pd.DataFrame()\n",
    "\n",
    "    for key, model in models_dict.items():\n",
    "\n",
    "        print('\\n', key, '--> Executing...') \n",
    "        \n",
    "        # Getting the results - Iterating n times the CV procedure\n",
    "        model_result_no_smote, sd_dict = cv_iteration(model, X, y, iterations=iterations, folds=folds)\n",
    "        # print(model_result_no_smote)\n",
    "        # print(sd_dict)\n",
    "\n",
    "        for k, v in model_result_no_smote.items():\n",
    "            model_result_no_smote[k] = str(round(v, 3)) + ' +/- ' + str(round(sd_dict[k], 2))\n",
    "\n",
    "        # Preparing the result dicts to be appended to the final DF \n",
    "        new_row_no_smote = pd.Series(data=model_result_no_smote, name=key)\n",
    "        # new_row_smote = pd.Series(data=model_result_smote, name=key)\n",
    "        # print(new_row_no_smote)\n",
    "        \n",
    "        # Append the results to the final DataFrame \n",
    "        results_no_smote_df = results_no_smote_df.append(new_row_no_smote, ignore_index=False)\n",
    "        # results_smote_df = results_smote_df.append(new_row_smote, ignore_index=False)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "    # Arranging the order of the columns\n",
    "    cols = list(results_no_smote_df.columns)\n",
    "    acc, auc = cols.index('accuracy'), cols.index('auc')\n",
    "    cols[auc], cols[acc] = cols[acc], cols[auc]\n",
    "\n",
    "    results_no_smote_df = results_no_smote_df[cols]\n",
    "    # results_smote_df = results_smote_df[cols]\n",
    "\n",
    "    # Sorting the models by the results of the AUC metric\n",
    "    results_no_smote_df = results_no_smote_df.sort_values(['auc'], ascending=False)\n",
    "    # results_smote_df = results_smote_df.sort_values(['auc'], ascending=False)\n",
    "\n",
    "    return results_no_smote_df #, results_smote_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "# Importing the Dataset\n",
    "lisbon_coimbra_df = pd.read_excel('190 proteins quantified_analysis.xls', sheet_name='Lisbon_Coimbra_proteomics')\n",
    "\n",
    "# Generating the y array\n",
    "y = np.array([1 if i == 'Amyloid-Positive' else 2 for i in lisbon_coimbra_df['Group']]) # 1 -> A+ ; 2 -> A-\n",
    "\n",
    "# Dropping the useless columns\n",
    "lisbon_coimbra_df = lisbon_coimbra_df.drop(['Sample Name','Group'], axis=1)\n",
    "\n",
    "# # Generating the X array \n",
    "X = lisbon_coimbra_df.values\n",
    "\n",
    "\n",
    "models_dict = {'SVM': svm_model, \n",
    "                'NB': nb_model,\n",
    "                'kNN': knn_model,\n",
    "                'DT': dt_model}\n",
    "\n",
    "lisbon_coimbra_no_smote_df = cross_validate(models_dict, X, y, iterations=10, folds=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " SVM --> Executing...\n",
      "0.0% -> 20.0% -> 40.0% -> 60.0% -> 80.0% -> \n",
      " NB --> Executing...\n",
      "0.0% -> 20.0% -> 40.0% -> 60.0% -> 80.0% -> \n",
      " kNN --> Executing...\n",
      "0.0% -> 20.0% -> 40.0% -> 60.0% -> 80.0% -> \n",
      " DT --> Executing...\n",
      "0.0% -> 20.0% -> 40.0% -> 60.0% -> 80.0% -> Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "lisbon_coimbra_no_smote_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.832 +/- 0.01</td>\n",
       "      <td>0.834 +/- 0.01</td>\n",
       "      <td>0.844 +/- 0.01</td>\n",
       "      <td>0.838 +/- 0.01</td>\n",
       "      <td>0.868 +/- 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.824 +/- 0.02</td>\n",
       "      <td>0.825 +/- 0.02</td>\n",
       "      <td>0.83 +/- 0.02</td>\n",
       "      <td>0.847 +/- 0.02</td>\n",
       "      <td>0.838 +/- 0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.735 +/- 0.02</td>\n",
       "      <td>0.742 +/- 0.01</td>\n",
       "      <td>0.778 +/- 0.01</td>\n",
       "      <td>0.731 +/- 0.01</td>\n",
       "      <td>0.846 +/- 0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.652 +/- 0.02</td>\n",
       "      <td>0.662 +/- 0.02</td>\n",
       "      <td>0.719 +/- 0.01</td>\n",
       "      <td>0.654 +/- 0.02</td>\n",
       "      <td>0.816 +/- 0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                auc        accuracy              f1       precision  \\\n",
       "NB   0.832 +/- 0.01  0.834 +/- 0.01  0.844 +/- 0.01  0.838 +/- 0.01   \n",
       "DT   0.824 +/- 0.02  0.825 +/- 0.02   0.83 +/- 0.02  0.847 +/- 0.02   \n",
       "SVM  0.735 +/- 0.02  0.742 +/- 0.01  0.778 +/- 0.01  0.731 +/- 0.01   \n",
       "kNN  0.652 +/- 0.02  0.662 +/- 0.02  0.719 +/- 0.01  0.654 +/- 0.02   \n",
       "\n",
       "             recall  \n",
       "NB   0.868 +/- 0.01  \n",
       "DT   0.838 +/- 0.03  \n",
       "SVM  0.846 +/- 0.02  \n",
       "kNN  0.816 +/- 0.02  "
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "model_result = {'auc': 0.650452380952381, 'accuracy': 0.6610897435897436, 'f1': 0.715760515885903, 'precision': 0.6497922077922078, 'recall': 0.8135714285714}\n",
    "sd = {'auc': 0.016051645672584026, 'accuracy': 0.016677018481450392, 'f1': 0.016981700695697755, 'precision': 0.012600357189387828, 'recall': 0.028433197358336958}\n",
    "\n",
    "for k, v in model_result.items():\n",
    "    model_result[k] = str(round(v, 3)) + ' +/- ' + str(round(sd[k], 2))\n",
    "\n",
    "new_row = pd.Series(data=model_result, name=key)\n",
    "print(new_row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "auc           0.65 +/- 0.02\n",
      "accuracy     0.661 +/- 0.02\n",
      "f1           0.716 +/- 0.02\n",
      "precision     0.65 +/- 0.01\n",
      "recall       0.814 +/- 0.03\n",
      "Name: xgb, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recursive Feature Elimination & Addition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import shuffle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Importing the Dataset\n",
    "lisbon_coimbra_df = pd.read_excel('190 proteins quantified_analysis.xls', sheet_name='Lisbon_Coimbra_proteomics')\n",
    "\n",
    "# REMOVEEEEE --- It's to reduce the dimensions of the dataset\n",
    "lisbon_coimbra_df = shuffle(lisbon_coimbra_df)[:30].reset_index().drop('index', axis=1) # Removing the n of examples\n",
    "lisbon_coimbra_df = lisbon_coimbra_df.iloc[: , :31] # Removing the features\n",
    "\n",
    "print(f'The dataset has: {lisbon_coimbra_df.shape[0]} examples and {lisbon_coimbra_df.shape[1]} features \\n')\n",
    "\n",
    "# Generating the y array\n",
    "y = np.array([1 if i == 'Amyloid-Positive' else 2 for i in lisbon_coimbra_df['Group']]) # 1 -> A+ ; 2 -> A-\n",
    "print(f'- The number of Amyloid-Positive patients is: {list(y).count(1)} \\n- The number of Amyloid-Negative patients is: {list(y).count(2)} \\n')\n",
    "\n",
    "# Dropping the useless columns\n",
    "lisbon_coimbra_df = lisbon_coimbra_df.drop(['Sample Name','Group'], axis=1)\n",
    "\n",
    "# Generating the X array \n",
    "X = lisbon_coimbra_df.values\n",
    "print(f'The final X matrix is made out of: {X.shape[0]} examples and {X.shape[1]} features')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dataset has: 30 examples and 31 features \n",
      "\n",
      "- The number of Amyloid-Positive patients is: 13 \n",
      "- The number of Amyloid-Negative patients is: 17 \n",
      "\n",
      "The final X matrix is made out of: 30 examples and 29 features\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining the function that I will use"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def svm_feat_importance(model, Dataset, X, y, iterations=100):\n",
    "\n",
    "    score_feature_dict_svm = {}\n",
    "\n",
    "    # Iterative method for feature importance:\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        if _ % 50 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f'{(_/iterations)*100}%')\n",
    "\n",
    "        # Generating the train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "        # Fitting the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        imps = permutation_importance(model, X_test, y_test)\n",
    "\n",
    "        # Storing the important features\n",
    "        feat_importance_svm = imps['importances_mean']\n",
    "\n",
    "        print(feat_importance_svm)\n",
    "\n",
    "        # Adding the importance score of the features to the dictionary\n",
    "        for idx, score in enumerate(feat_importance_svm):\n",
    "            if Dataset.keys()[idx] in score_feature_dict_svm.keys():\n",
    "                score_feature_dict_svm[Dataset.keys()[idx]].append(score)\n",
    "            else:\n",
    "                score_feature_dict_svm[Dataset.keys()[idx]] = [score]\n",
    "\n",
    "    score_feature_dict_svm = {k: np.mean(v) for k, v in score_feature_dict_svm.items()}\n",
    "\n",
    "    features_svm_sorted = dict(sorted(score_feature_dict_svm.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    feature_importance_name_svm = list(features_svm_sorted.keys())\n",
    "\n",
    "    return features_svm_sorted, feature_importance_name_svm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Feature Addition**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def feature_addition_svm(Dataset, model, y):\n",
    "\n",
    "    final_rank = []\n",
    "\n",
    "    for i in range(len(Dataset.keys())):\n",
    "\n",
    "        print(i)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        score_feat_imp_svm = {}\n",
    "\n",
    "        iteration = 15\n",
    "        for _ in range(iteration):\n",
    "            \n",
    "            # y = np.array([1 if i == 'Amyloid-Positive' else 2 for i in lisbon_coimbra_df['Group']])\n",
    "            X = Dataset.values\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "            # Fitting the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Extracting the most important features\n",
    "            imps = permutation_importance(model, X_test, y_test)\n",
    "\n",
    "            feat_imp_svm = imps['importances_mean']\n",
    "\n",
    "            for idx, score in enumerate(feat_imp_svm):\n",
    "                if Dataset.keys()[idx] in score_feat_imp_svm.keys():\n",
    "                    score_feat_imp_svm[Dataset.keys()[idx]].append(score)\n",
    "                else:\n",
    "                    score_feat_imp_svm[Dataset.keys()[idx]] = [score]\n",
    "\n",
    "        # print(score_feat_imp_svm)\n",
    "        score_feat_imp_svm = {k: np.mean(v) for k, v in score_feat_imp_svm.items()}\n",
    "        \n",
    "        # Sorting\n",
    "        features_svm_sorted = dict(sorted(score_feat_imp_svm.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        # print(features_svm_sorted)\n",
    "\n",
    "        best_feat = list(features_svm_sorted.keys())[0]\n",
    "\n",
    "        final_rank.append(best_feat)\n",
    "\n",
    "        Dataset = Dataset.drop(best_feat, axis=1)\n",
    "\n",
    "    print(final_rank)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "feature_addition_svm(lisbon_coimbra_df, svm_model, y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['P02768_ALBU', 'P01011_AACT', 'P01019_ANGT', 'P01024_CO3', 'P02766_TTHY', 'P00450_CERU', 'P0DOX5_IGG1', 'P41222_PTGDS', 'P10909_CLUS', 'P02787_TRFE', 'P02649_APOE', 'P02790_HEMO', 'P02774_VTDB', 'P02647_APOA1', 'P01009_A1AT', 'O94985_CSTN1', 'P02749_APOH', 'P09871_C1S', 'P06396_GELS', 'P01023_A2MG', 'P02751_FINC', 'P23142_FBLN1', 'Q13822_ENPP2', 'Q92823_NRCAM', 'P02679_FIBG', 'P05155_IC1', 'Q96KN2_CNDP1', 'Q12860_CNTN1', 'P08603_CFAH']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Feature Elimination**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def feature_elimination_svm(Dataset, model, y):\n",
    "\n",
    "    final_rank = []\n",
    "\n",
    "    for i in range(len(Dataset.keys())):\n",
    "\n",
    "        print(i)\n",
    "        # clear_output(wait=True)\n",
    "\n",
    "        score_feat_imp_svm = {}\n",
    "\n",
    "        iteration = 10\n",
    "        for _ in range(iteration):\n",
    "\n",
    "            # y = np.array([1 if i == 'Amyloid-Positive' else 2 for i in lisbon_coimbra_df['Group']])\n",
    "            X = Dataset.values\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "            # Fitting the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Extracting the most important features\n",
    "            imps = permutation_importance(model, X_test, y_test)\n",
    "\n",
    "            feat_imp_svm = imps['importances_mean']\n",
    "\n",
    "            for idx, score in enumerate(feat_imp_svm):\n",
    "                if Dataset.keys()[idx] in score_feat_imp_svm.keys():\n",
    "                    score_feat_imp_svm[Dataset.keys()[idx]].append(score)\n",
    "                else:\n",
    "                    score_feat_imp_svm[Dataset.keys()[idx]] = [score]\n",
    "\n",
    "        score_feat_imp_svm = {k: np.mean(v) for k, v in score_feat_imp_svm.items()}\n",
    "        \n",
    "        # Sorting\n",
    "        features_svm_sorted = dict(sorted(score_feat_imp_svm.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "        print(features_svm_sorted)\n",
    "\n",
    "        worst_feat = list(features_svm_sorted.keys())[len(features_svm_sorted) - 1]    \n",
    "\n",
    "        final_rank.insert(0, worst_feat)\n",
    "\n",
    "        Dataset = Dataset.drop(worst_feat, axis=1)\n",
    "\n",
    "    print(final_rank)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "feature_elimination_svm(lisbon_coimbra_df, svm_model, y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "{'P02768_ALBU': 0.0225, 'P01024_CO3': 0.0075, 'P02787_TRFE': 0.005, 'P01011_AACT': 0.0025, 'P02766_TTHY': 0.0025, 'P10909_CLUS': 0.0025, 'P01009_A1AT': 0.0, 'P41222_PTGDS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'P0DOX5_IGG1': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0, 'Q13822_ENPP2': 0.0, 'Q12860_CNTN1': 0.0, 'P02649_APOE': -0.017499999999999998}\n",
      "1\n",
      "{'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P41222_PTGDS': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P02787_TRFE': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0, 'Q13822_ENPP2': 0.0, 'Q12860_CNTN1': 0.0, 'P01009_A1AT': -0.0075, 'P02768_ALBU': -0.0125, 'P0DOX5_IGG1': -0.0125}\n",
      "2\n",
      "{'P02768_ALBU': 0.015000000000000003, 'P01009_A1AT': 0.01, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P41222_PTGDS': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P02787_TRFE': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0, 'Q13822_ENPP2': 0.0, 'Q12860_CNTN1': 0.0}\n",
      "3\n",
      "{'P10909_CLUS': 0.0125, 'P02787_TRFE': 0.0125, 'P02766_TTHY': 0.01, 'P01024_CO3': 0.0075, 'P01019_ANGT': 0.005, 'P02768_ALBU': 0.0, 'P01011_AACT': 0.0, 'P41222_PTGDS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0, 'Q13822_ENPP2': 0.0, 'P01009_A1AT': -0.0125}\n",
      "4\n",
      "{'P02768_ALBU': 0.0, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P41222_PTGDS': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P02787_TRFE': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0, 'Q13822_ENPP2': 0.0}\n",
      "5\n",
      "{'P02647_APOA1': 0.0125, 'P02766_TTHY': 0.01, 'P10909_CLUS': 0.01, 'P02768_ALBU': 0.005, 'P01011_AACT': 0.005, 'P02790_HEMO': 0.005, 'P02787_TRFE': 0.0025, 'P01019_ANGT': 0.0025, 'P01024_CO3': 0.0, 'P41222_PTGDS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0, 'P08603_CFAH': 0.0}\n",
      "6\n",
      "{'P02768_ALBU': 0.04, 'P01024_CO3': 0.0075, 'P02774_VTDB': 0.0075, 'P02766_TTHY': 0.005, 'P10909_CLUS': 0.005, 'P02790_HEMO': 0.005, 'P02787_TRFE': 0.0025, 'P01011_AACT': 0.0, 'P41222_PTGDS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0, 'P02679_FIBG': 0.0}\n",
      "7\n",
      "{'P02768_ALBU': 0.034999999999999996, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P41222_PTGDS': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P02787_TRFE': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0, 'O94985_CSTN1': 0.0, 'P05155_IC1': 0.0}\n",
      "8\n",
      "{'P02768_ALBU': 0.025, 'P02749_APOH': 0.017499999999999998, 'P02766_TTHY': 0.0125, 'P02790_HEMO': 0.0125, 'P02774_VTDB': 0.0125, 'P01019_ANGT': 0.0125, 'P02647_APOA1': 0.01, 'P01024_CO3': 0.009999999999999998, 'P01011_AACT': 0.0075, 'P41222_PTGDS': 0.0025, 'P10909_CLUS': 0.0025, 'P02787_TRFE': 1.3877787807814458e-18, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P23142_FBLN1': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'O94985_CSTN1': 0.0}\n",
      "9\n",
      "{'P02768_ALBU': 0.017499999999999998, 'P10909_CLUS': 0.015000000000000003, 'P02787_TRFE': 0.005, 'P01024_CO3': 0.0025, 'P02766_TTHY': 0.0025, 'P01011_AACT': 0.0, 'P41222_PTGDS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02647_APOA1': 0.0}\n",
      "10\n",
      "{'P02768_ALBU': 0.027500000000000004, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P41222_PTGDS': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02766_TTHY': -0.0025, 'P02787_TRFE': -0.0025}\n",
      "11\n",
      "{'P02768_ALBU': 0.0075000000000000015, 'P01024_CO3': 0.0025, 'P01011_AACT': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0, 'P02766_TTHY': -0.0024999999999999996, 'P10909_CLUS': -0.005, 'P41222_PTGDS': -0.0075}\n",
      "12\n",
      "{'P02768_ALBU': 0.02, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'Q92823_NRCAM': 0.0}\n",
      "13\n",
      "{'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0, 'P02768_ALBU': -0.025}\n",
      "14\n",
      "{'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P10909_CLUS': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02751_FINC': 0.0}\n",
      "15\n",
      "{'P02790_HEMO': 0.005, 'P01019_ANGT': 0.0025, 'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0, 'P02766_TTHY': -0.0025, 'P10909_CLUS': -0.0075}\n",
      "16\n",
      "{'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0, 'P02749_APOH': 0.0}\n",
      "17\n",
      "{'P01024_CO3': 0.0, 'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P01019_ANGT': 0.0, 'Q96KN2_CNDP1': 0.0}\n",
      "18\n",
      "{'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P23142_FBLN1': 0.0, 'P02766_TTHY': -0.0025, 'P01019_ANGT': -0.0125, 'P01011_AACT': -0.015, 'P01024_CO3': -0.0225}\n",
      "19\n",
      "{'P01019_ANGT': 0.034999999999999996, 'P02766_TTHY': 0.017499999999999998, 'P01011_AACT': 0.015000000000000003, 'P02774_VTDB': 0.0025, 'P02790_HEMO': 0.0024999999999999996, 'P00450_CERU': 0.0, 'P06396_GELS': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P23142_FBLN1': 0.0}\n",
      "20\n",
      "{'P02766_TTHY': 0.0225, 'P02790_HEMO': 0.02, 'P02774_VTDB': 0.0075, 'P01019_ANGT': 0.0025, 'P01011_AACT': 0.0, 'P01023_A2MG': -0.005, 'P09871_C1S': -0.0075, 'P00450_CERU': -0.01, 'P06396_GELS': -0.01}\n",
      "21\n",
      "{'P01011_AACT': 0.0, 'P02766_TTHY': 0.0, 'P00450_CERU': 0.0, 'P02790_HEMO': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P01019_ANGT': 0.0}\n",
      "22\n",
      "{'P02766_TTHY': 0.0, 'P00450_CERU': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0, 'P01011_AACT': -0.005, 'P02790_HEMO': -0.025}\n",
      "23\n",
      "{'P02766_TTHY': 0.0125, 'P01011_AACT': 0.005, 'P00450_CERU': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02774_VTDB': 0.0}\n",
      "24\n",
      "{'P01011_AACT': 0.005, 'P00450_CERU': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0, 'P02766_TTHY': -0.0025}\n",
      "25\n",
      "{'P01011_AACT': 0.045, 'P00450_CERU': 0.0, 'P01023_A2MG': 0.0, 'P09871_C1S': 0.0}\n",
      "26\n",
      "{'P00450_CERU': 0.0, 'P01023_A2MG': 0.0, 'P01011_AACT': -0.005}\n",
      "27\n",
      "{'P00450_CERU': 0.0075, 'P01023_A2MG': -0.0075}\n",
      "28\n",
      "{'P00450_CERU': 0.0}\n",
      "['P00450_CERU', 'P01023_A2MG', 'P01011_AACT', 'P09871_C1S', 'P02766_TTHY', 'P02774_VTDB', 'P02790_HEMO', 'P01019_ANGT', 'P06396_GELS', 'P23142_FBLN1', 'P01024_CO3', 'Q96KN2_CNDP1', 'P02749_APOH', 'P10909_CLUS', 'P02751_FINC', 'P02768_ALBU', 'Q92823_NRCAM', 'P41222_PTGDS', 'P02787_TRFE', 'P02647_APOA1', 'O94985_CSTN1', 'P05155_IC1', 'P02679_FIBG', 'P08603_CFAH', 'Q13822_ENPP2', 'P01009_A1AT', 'Q12860_CNTN1', 'P0DOX5_IGG1', 'P02649_APOE']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "06cb67651ce969e244f20f184e33f4ddb1106793adfe07cf7ddc131c95c4012f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}